# AutoNews 功能更新说明

## 更新日期：2026-02-07

### ✅ 新增功能

#### 1. 每个新闻源单独保存文件
之前所有新闻源的文章都保存在同一个文件中，导致内容被覆盖。现在每个源单独保存：

**文件命名格式：**
```
日期_源名称_标签.json
日期_源名称_标签.md
```

**示例：**
```
2026-02-07_it之家_科技_it.json
2026-02-07_v2ex_技术_社区.json
2026-02-07_solidot_科技_开源.json
2026-02-07_hackernews_tech_international.json
```

#### 2. 完整文章内容抓取
不再只保存RSS中的摘要，而是访问每篇文章的原文链接，获取完整内容！

**新增组件：**
- `ContentExtractor` - 智能内容提取器
  - 自动识别文章主体内容
  - 支持多种HTML结构
  - 自动清理广告和无关元素
  - 处理中英文编码

**提取策略（按优先级）：**
1. 查找标准article标签
2. 查找常见class名称（content, article, post等）
3. 提取所有段落文本
4. 作为最后备选，提取body全文

**效果对比：**
- 之前：只有RSS摘要（50-200字）
- 现在：完整文章内容（500-10000字）

#### 3. 限制每源文章数量为10篇
修改配置文件，每个源只抓取前10篇最新文章，提高效率。

### 📊 测试结果

```bash
✅ 成功抓取 40 篇文章（4个源 x 10篇）

文件列表：
- 2026-02-07_it之家_科技_it.json (31KB)
- 2026-02-07_solidot_科技_开源.json (16KB)  
- 2026-02-07_v2ex_技术_社区.json (17KB)
- 2026-02-07_hackernews_tech_international.json (53KB)

对应的Markdown文件：
- 2026-02-07_it之家_科技_it.md
- 2026-02-07_solidot_科技_开源.md
- 2026-02-07_v2ex_技术_社区.md
- 2026-02-07_hackernews_tech_international.md
```

### 🔧 技术实现

#### ContentExtractor类
```python
class ContentExtractor:
    """从URL提取完整文章内容"""
    
    def extract(self, url: str) -> Optional[str]:
        # 1. 访问URL获取HTML
        # 2. 识别文章主体（多种策略）
        # 3. 清理无关内容
        # 4. 返回纯文本
```

#### 修改的文件
1. **src/fetchers/content_extractor.py** (新增) - 内容提取器
2. **src/storage/json_storage.py** - 修改文件名生成逻辑
3. **src/storage/markdown_storage.py** - 修改文件名和标题生成
4. **main.py** - 集成内容提取，按源分别处理和保存
5. **config/sources.yaml** - 修改max_articles_per_source: 10

### 📝 数据格式示例

#### JSON格式
```json
[
  {
    "title": "文章标题",
    "url": "https://example.com/article/123",
    "source": "IT之家",
    "category": "全部",
    "published_date": "2026-02-07T10:30:00",
    "content": "这是从原文链接提取的完整文章内容，包含所有段落...",
    "summary": "自动生成的摘要...",
    "tags": ["科技", "IT"],
    "hash": "abc123..."
  }
]
```

#### Markdown格式
```markdown
# News Summary - IT之家 / 全部
## February 07, 2026

Total articles: 10

---

### 文章标题

**Published:** 2026-02-07 10:30
**Link:** [https://example.com/article/123](...)
**Tags:** 科技, IT

**Summary:**
自动生成的摘要内容...

---
```

### 💡 使用方法

#### 1. 运行抓取
```bash
cd /home/temp/autonews
source venv/bin/activate
python main.py --once
```

#### 2. 查看结果
```bash
# 查看所有生成的文件
ls -lh data/processed/
ls -lh data/exports/

# 查看特定源的文章
cat data/processed/2026-02-07_it之家_科技_it.json | jq '.'

# 阅读Markdown报告
cat data/exports/2026-02-07_v2ex_技术_社区.md
```

#### 3. 配置调整

**修改文章数量：**
编辑 `config/sources.yaml`
```yaml
fetch_settings:
  max_articles_per_source: 5  # 改为每源5篇
```

**调整超时时间：**
```yaml
fetch_settings:
  timeout: 20  # 增加到20秒（如果网站访问慢）
```

### ⚡ 性能说明

**抓取时间：**
- 每篇文章额外需要1-3秒访问原文
- 10篇文章约需10-30秒
- 4个源并行处理，总时间约1-2分钟

**文件大小：**
- 完整内容的JSON文件：15-50KB（之前只有3-5KB）
- 包含更多可用信息，适合离线阅读

### 🎯 优势

1. **完整内容** - 不再依赖RSS摘要，获取完整文章
2. **离线可读** - 即使原文链接失效，本地仍有完整内容
3. **付费内容** - 部分网站的付费墙内容也能在首次访问时获取
4. **独立文件** - 每个源单独保存，互不影响
5. **清晰命名** - 文件名包含日期、源名称、标签，易于查找

### 📌 注意事项

1. **访问限制**
   - 某些网站可能有反爬虫措施
   - 付费墙后的内容可能无法完全获取
   - JavaScript动态加载的内容暂不支持

2. **网络要求**
   - 需要稳定的网络连接
   - 某些国外网站可能访问较慢

3. **磁盘空间**
   - 完整内容占用更多空间
   - 建议定期清理旧文件

### 🔄 下一步优化

- [ ] 添加并发下载（加快抓取速度）
- [ ] 支持JavaScript渲染（Selenium/Playwright）
- [ ] 智能识别付费内容
- [ ] 文章去重优化（同一文章不同源）
- [ ] 添加图片下载功能

---

**更新完成！** ✅

现在AutoNews可以：
1. 每个源独立保存文件
2. 获取完整文章内容
3. 限制每源10篇文章
4. 生成清晰的文件名
